###### In the following C++ function, let n >= m.
```cpp
    int gcd(int n, int m) {
    if (n%m ==0) return m;
    if (n < m) swap(n, m);
    while (m > 0) {
        n = n%m;
        swap(n, m);
    }
    return n;
}
```
###### What is the time complexity of the above function assuming n > m?.  
###### Θ symbol represents theta notation and Ω symbol represents omega notation.


---
## *Solution*
### Time Complexity:

The provided function is an implementation of the Euclidean algorithm for finding the greatest common divisor (GCD) of two integers n and m

Step 1:  
if (n % m == 0) return m;  
This is a quick check to see if m divides n perfectly. This takes constant time, O(1), since it's just a modulus operation.

Step 2:  
if (n < m) swap(n, m);  
This step ensures that n >= m by swapping the values of n and m if n is smaller than m. The swap operation takes constant time, O(1).

Step 3 - 5:  
The while loop while (m > 0) is the main part of the algorithm. In each iteration:  
Step 4: n = n % m; — The modulus operation computes the remainder of n divided by m. This operation takes O(1) time.  
Step 5: swap(n, m); — The swap operation takes O(1) time.

The loop continues until m becomes 0. The critical part to analyze is how many times this loop runs.

Time Complexity Analysis:  
The Euclidean algorithm reduces the size of the numbers involved by taking the modulus. Specifically:  
After each iteration of the loop, the value of m reduces because we replace n with n % m, and m becomes the old n.  
In the worst case, the size of the numbers in each iteration decreases approximately by half in each step.

To analyze the number of iterations, let's focus on the behavior of the values of n and m:  
In each step, the size of the problem reduces significantly, with m becoming the remainder of n % m. Since the remainder is always smaller than m, the size of the numbers involved shrinks at a relatively fast rate.  
The number of iterations is proportional to the number of divisions required to reduce n and m to their GCD.

The number of iterations is bounded by the number of times we can divide n and m by approximately half. In the worst case, the number of iterations is proportional to the logarithm of the smaller number (since the values reduce rapidly). Specifically, the number of iterations is O(logmin(n,m)), which is the number of times we can divide n by m (or vice versa) until one of the values becomes zero.

Thus, the time complexity is O(logmin(n,m)).

***Theta Notation (Θ):***
Since the number of iterations is proportional to the logarithm of the smaller of n and m, the exact time complexity (tight bound) is:  
Θ(log⁡min⁡(n,m))  
This means the time complexity grows logarithmically with respect to the smaller of the two inputs.

***Omega Notation (Ω):***
The best-case time complexity corresponds to the case where n % m == 0 immediately, which results in returning m without entering the loop. This is an O(1)O(1) operation.  
Thus, the lower bound is:  
Ω(1)

Summary:  
Time Complexity (Θ): Θ(log⁡min⁡(n,m))  
Best-case Time Complexity (Ω): Ω(1)
Worst-case Time Complexity (O): O(logmin(n,m))